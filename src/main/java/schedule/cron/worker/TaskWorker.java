package schedule.cron.worker;

import com.fasterxml.jackson.databind.ObjectMapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Component;
import schedule.cron.model.*;
import schedule.cron.mongo.DagRepository;
import schedule.cron.mongo.TaskInstanceOps;
import schedule.cron.mongo.TaskInstanceRepository;
import schedule.cron.publisher.TaskPublisher;
import schedule.cron.task.Task;
import schedule.cron.task.TaskFactory;

import java.util.*;
import java.util.stream.Collectors;

@Component
public class TaskWorker {

    private static final Logger log = LoggerFactory.getLogger(TaskWorker.class);

    private final TaskInstanceOps ops;
    private final TaskInstanceRepository taskRepo;
    private final DagRepository dagRepo;
    private final TaskPublisher taskPublisher;
    private final ObjectMapper objectMapper;

    public TaskWorker(
            TaskInstanceOps ops,
            TaskInstanceRepository taskRepo,
            DagRepository dagRepo,
            TaskPublisher taskPublisher,
            ObjectMapper objectMapper) {
        this.ops = ops;
        this.taskRepo = taskRepo;
        this.dagRepo = dagRepo;
        this.taskPublisher = taskPublisher;
        this.objectMapper = objectMapper;
    }

    /**
     * æ¶ˆè´¹ task-print ç±»å‹çš„ä»»åŠ¡
     */
    @KafkaListener(topics = "task-print", groupId = "worker-print", concurrency = "3")
    public void consumePrintTask(String message, Acknowledgment ack) {
        processTask(message, ack);
    }

//    /**
//     * æ¶ˆè´¹ task-email ç±»å‹çš„ä»»åŠ¡
//     */
//    @KafkaListener(topics = "task-email", groupId = "worker-email", concurrency = "2")
//    public void consumeEmailTask(String message, Acknowledgment ack) {
//        processTask(message, ack);
//    }
//
//    /**
//     * æ¶ˆè´¹ task-http ç±»å‹çš„ä»»åŠ¡
//     */
//    @KafkaListener(topics = "task-http", groupId = "worker-http", concurrency = "5")
//    public void consumeHttpTask(String message, Acknowledgment ack) {
//        processTask(message, ack);
//    }

    // âœ… é€šç”¨ä»»åŠ¡å¤„ç†é€»è¾‘
    private void processTask(String message, Acknowledgment ack) {
        TaskInstance ti = null;
        try {
            ti = objectMapper.readValue(message, TaskInstance.class);
            log.info("ğŸ“¥ Received task: id={}, taskName={}, ti={}",
                    ti.getId(), ti.getTaskName(),ti);

            // 1. åŸå­æ›´æ–°çŠ¶æ€ NONE -> RUNNING
            if (!ops.markRunning(ti.getId())) {
                log.warn("âš ï¸ Task already running or completed: {}", ti.getId());
                ack.acknowledge();
                return;
            }

            // 2. è·å–ä»»åŠ¡å®ç°
            Task task = TaskFactory.get(ti.getTaskName());
            if (task == null) {
                log.error("âŒ Task implementation not found: {}", ti.getTaskName());
                markFailed(ti);
                ack.acknowledge();
                return;
            }

            // 3. æ‰§è¡Œä»»åŠ¡
            log.info("ğŸš€ Executing task: {} ", ti.getTaskName());
            task.execute(ti);

            // 4. æ ‡è®°æˆåŠŸ
            ti = taskRepo.save(ti.toBuilder()
                    .status(TaskInstanceStatus.SUCCESS)
                    .endTime(System.currentTimeMillis())
                    .build());

            log.info("âœ… Task completed: {}", ti.getId());

            // 5. âœ… è§¦å‘ä¸‹æ¸¸ä»»åŠ¡
            triggerDownstreamTasks(ti);

            // 6. âœ… æ£€æŸ¥ DagRun æ˜¯å¦å®Œæˆ
            checkDagRunCompletion(ti.getDagRunId());

            ack.acknowledge();

        } catch (Exception e) {
            log.error("âŒ Task execution failed: " + (ti != null ? ti.getId() : "unknown"), e);
            if (ti != null) {
                markFailed(ti);
            }
            ack.acknowledge();
        }
    }

    /**
     * âœ… è§¦å‘ä¸‹æ¸¸ä»»åŠ¡
     */
    private void triggerDownstreamTasks(TaskInstance completedTask) {
        try {
            // 1. è·å– DAG å®šä¹‰
            Dag dag = dagRepo.findById(completedTask.getDagId()).orElse(null);
            if (dag == null) {
                log.error("DAG not found: {}", completedTask.getDagId());
                return;
            }

            // 2. æ‰¾åˆ°ä¾èµ–è¿™ä¸ªä»»åŠ¡çš„ä¸‹æ¸¸ä»»åŠ¡
            List<String> downstreamTaskIds = new ArrayList<>();
            dag.getTasks().forEach((taskId, def) -> {
                List<String> upstream = def.getUpstream();
                if (upstream != null && upstream.contains(completedTask.getTaskName())) {
                    downstreamTaskIds.add(taskId);
                }
            });

            if (downstreamTaskIds.isEmpty()) {
                log.debug("No downstream tasks for: {}", completedTask.getTaskName());
                return;
            }

            log.info("Found {} downstream tasks for: {}",
                    downstreamTaskIds.size(), completedTask.getTaskName());

            // 3. æŸ¥è¯¢è¿™äº›ä¸‹æ¸¸ä»»åŠ¡çš„ TaskInstance
            List<TaskInstance> downstreamTasks = taskRepo.findByDagRunIdAndTaskNameIn(
                    completedTask.getDagRunId(),
                    downstreamTaskIds
            );

            // 4. æ£€æŸ¥æ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„ä¾èµ–æ˜¯å¦éƒ½å®Œæˆ
            for (TaskInstance downstreamTask : downstreamTasks) {
                if (downstreamTask.getStatus() != TaskInstanceStatus.NONE) {
                    continue; // å·²ç»å¤„ç†è¿‡äº†
                }

                TaskDefinition taskDef = dag.getTasks().get(downstreamTask.getTaskName());

                // æ£€æŸ¥æ‰€æœ‰ upstream æ˜¯å¦éƒ½æˆåŠŸ
                if (allUpstreamCompleted(completedTask.getDagRunId(), taskDef.getUpstream())) {
                    log.info("ğŸŸ¢ All upstream completed, publishing downstream task: {}",
                            downstreamTask.getTaskName());
                    taskPublisher.publishTask(downstreamTask);
                } else {
                    log.debug("â³ Waiting for upstream tasks: {}", downstreamTask.getTaskName());
                }
            }

        } catch (Exception e) {
            log.error("Error triggering downstream tasks", e);
        }
    }

    /**
     * æ£€æŸ¥æ‰€æœ‰ upstream ä»»åŠ¡æ˜¯å¦éƒ½æˆåŠŸ
     */
    private boolean allUpstreamCompleted(String dagRunId, List<String> upstreamTaskIds) {
        if (upstreamTaskIds == null || upstreamTaskIds.isEmpty()) {
            return true;
        }

        List<TaskInstance> upstreamTasks = taskRepo.findByDagRunIdAndTaskNameIn(
                dagRunId,
                upstreamTaskIds
        );

        return upstreamTasks.stream()
                .allMatch(t -> t.getStatus() == TaskInstanceStatus.SUCCESS);
    }

    /**
     * âœ… æ£€æŸ¥ DagRun æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
     */
    private void checkDagRunCompletion(String dagRunId) {
        try {
            List<TaskInstance> allTasks = taskRepo.findByDagRunId(dagRunId);

            boolean allCompleted = allTasks.stream()
                    .allMatch(t -> t.getStatus() == TaskInstanceStatus.SUCCESS
                            || t.getStatus() == TaskInstanceStatus.FAILED);

            if (allCompleted) {
                log.info("ğŸ‰ All tasks completed for DagRun: {}", dagRunId);
                taskPublisher.publishDagCompletion(dagRunId);
            }

        } catch (Exception e) {
            log.error("Error checking DagRun completion", e);
        }
    }

    private void markFailed(TaskInstance ti) {
        try {
            taskRepo.save(ti.toBuilder()
                    .status(TaskInstanceStatus.FAILED)
                    .endTime(System.currentTimeMillis())
                    .build());
        } catch (Exception e) {
            log.error("Failed to mark task as FAILED: " + ti.getId(), e);
        }
    }
}